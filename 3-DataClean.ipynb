{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = os.path.join(os.getcwd(), 'data/squad_1.1/train-v1.1.json')\n",
    "data_dev_path =  os.path.join(os.getcwd(), 'data/squad_1.1/dev-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = json.load(open(data_train_path))\n",
    "data_dev = json.load(open(data_dev_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  87599\n",
      "Dev Data:  10570\n"
     ]
    }
   ],
   "source": [
    "ids_train, titles_train, contexts_train, questions_train, answers_train = [], [], [], [], []\n",
    "ids_dev, titles_dev, contexts_dev, questions_dev, answers_dev = [], [], [], [], []\n",
    "\n",
    "# Load Train Data on SQuAD 1.1\n",
    "for article in data_train[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_train.append(qa[\"id\"])\n",
    "            titles_train.append(title)\n",
    "            contexts_train.append(context)\n",
    "            questions_train.append(qa[\"question\"])\n",
    "            answers_train.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "# Load Dev Data on SQuAD 1.1\n",
    "for article in data_dev[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_dev.append(qa[\"id\"])\n",
    "            titles_dev.append(title)\n",
    "            contexts_dev.append(context)\n",
    "            questions_dev.append(qa[\"question\"])\n",
    "            answers_dev.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "print(\"Train Data: \", len(ids_train))\n",
    "print(\"Dev Data: \", len(ids_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial-SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_data_dev_path = os.path.join(os.getcwd(), 'data/squad_adv/none_n1000_k1_s0.json')\n",
    "adv_data_addonesent_path = os.path.join(os.getcwd(), 'data/squad_adv/sample1k-HCVerifySample.json')\n",
    "adv_data_addsent_path = os.path.join(os.getcwd(), 'data/squad_adv/sample1k-HCVerifyAll.json')\n",
    "adv_data_addmodsent_path = os.path.join(os.getcwd(), 'data/squad_adv/sample1k-HCVerifyModAll.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_data_dev = json.load(open(adv_data_dev_path))\n",
    "adv_data_addonesent = json.load(open(adv_data_addonesent_path))\n",
    "adv_data_addsent = json.load(open(adv_data_addsent_path))\n",
    "adv_data_addmodsent = json.load(open(adv_data_addmodsent_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled SQuAD Validation Data:  1000\n",
      "Adversarial SQuAD AddSent Data:  3560\n",
      "Adversarial SQuAD AddModSent Data:  3225\n",
      "Adversarial SQuAD AddOneSent Data:  1787\n"
     ]
    }
   ],
   "source": [
    "ids_adv_dev, titles_adv_dev, contexts_adv_dev, questions_adv_dev, answers_adv_dev = [], [], [], [], []\n",
    "ids_adv_addonesent, titles_adv_addonesent, contexts_adv_addonesent, questions_adv_addonesent, answers_adv_addonesent = [], [], [], [], []\n",
    "ids_adv_addsent, titles_adv_addsent, contexts_adv_addsent, questions_adv_addsent, answers_adv_addsent = [], [], [], [], []\n",
    "ids_adv_addmodsent, titles_adv_addmodsent, contexts_adv_addmodsent, questions_adv_addmodsent, answers_adv_addmodsent = [], [], [], [], []\n",
    "\n",
    "# Load randomly sampled 1k validation Data on SQuAD 1.1\n",
    "for article in adv_data_dev[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_adv_dev.append(qa[\"id\"])\n",
    "            titles_adv_dev.append(title)\n",
    "            contexts_adv_dev.append(context)\n",
    "            questions_adv_dev.append(qa[\"question\"])\n",
    "            answers_adv_dev.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "# Load adversarial data with addonesent on SQuAD 1.1\n",
    "for article in adv_data_addonesent[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_adv_addonesent.append(qa[\"id\"])\n",
    "            titles_adv_addonesent.append(title)\n",
    "            contexts_adv_addonesent.append(context)\n",
    "            questions_adv_addonesent.append(qa[\"question\"])\n",
    "            answers_adv_addonesent.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "# Load adversarial data with addsent on SQuAD 1.1\n",
    "for article in adv_data_addsent[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_adv_addsent.append(qa[\"id\"])\n",
    "            titles_adv_addsent.append(title)\n",
    "            contexts_adv_addsent.append(context)\n",
    "            questions_adv_addsent.append(qa[\"question\"])\n",
    "            answers_adv_addsent.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "# Load adversarial data with addmodsent on SQuAD 1.1\n",
    "for article in adv_data_addmodsent[\"data\"]:\n",
    "    title = article.get(\"title\", \"\")\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
    "            answer_texts = [answer[\"text\"] for answer in qa[\"answers\"]]\n",
    "            ids_adv_addmodsent.append(qa[\"id\"])\n",
    "            titles_adv_addmodsent.append(title)\n",
    "            contexts_adv_addmodsent.append(context)\n",
    "            questions_adv_addmodsent.append(qa[\"question\"])\n",
    "            answers_adv_addmodsent.append({\n",
    "                \"answer_start\": answer_starts,\n",
    "                \"text\": answer_texts\n",
    "            })\n",
    "print(\"Sampled SQuAD Validation Data: \", len(ids_adv_dev))\n",
    "print(\"Adversarial SQuAD AddSent Data: \", len(ids_adv_addsent))\n",
    "print(\"Adversarial SQuAD AddModSent Data: \", len(ids_adv_addmodsent))\n",
    "print(\"Adversarial SQuAD AddOneSent Data: \", len(ids_adv_addonesent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in ids_adv_dev:\n",
    "    if id not in set(ids_adv_addsent):\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in ids_adv_dev:\n",
    "    if id not in set(ids_adv_addonesent):\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in ids_adv_dev:\n",
    "    if id not in set(ids_adv_addmodsent):\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_adv_addonesent_only_adv, titles_adv_addonesent_only_adv, contexts_adv_addonesent_only_adv, questions_adv_addonesent_only_adv, answers_adv_addonesent_only_adv = [], [], [], [], []\n",
    "ids_adv_addsent_only_adv, titles_adv_addsent_only_adv, contexts_adv_addsent_only_adv, questions_adv_addsent_only_adv, answers_adv_addsent_only_adv = [], [], [], [], []\n",
    "ids_adv_addmodsent_only_adv, titles_adv_addmodsent_only_adv, contexts_adv_addmodsent_only_adv, questions_adv_addmodsent_only_adv, answers_adv_addmodsent_only_adv = [], [], [], [], []\n",
    "\n",
    "for i, id in enumerate(ids_adv_addonesent):\n",
    "    if id not in set(ids_adv_dev):\n",
    "        ids_adv_addonesent_only_adv.append(id)\n",
    "        titles_adv_addonesent_only_adv.append(titles_adv_addonesent[i])\n",
    "        contexts_adv_addonesent_only_adv.append(contexts_adv_addonesent[i])\n",
    "        questions_adv_addonesent_only_adv.append(questions_adv_addonesent[i])\n",
    "        answers_adv_addonesent_only_adv.append(answers_adv_addonesent[i])\n",
    "\n",
    "for i, id in enumerate(ids_adv_addsent):\n",
    "    if id not in set(ids_adv_dev):\n",
    "        ids_adv_addsent_only_adv.append(id)\n",
    "        titles_adv_addsent_only_adv.append(titles_adv_addsent[i])\n",
    "        contexts_adv_addsent_only_adv.append(contexts_adv_addsent[i])\n",
    "        questions_adv_addsent_only_adv.append(questions_adv_addsent[i])\n",
    "        answers_adv_addsent_only_adv.append(answers_adv_addsent[i])\n",
    "\n",
    "for i, id in enumerate(ids_adv_addmodsent):\n",
    "    if id not in set(ids_adv_dev):\n",
    "        ids_adv_addmodsent_only_adv.append(id)\n",
    "        titles_adv_addmodsent_only_adv.append(titles_adv_addmodsent[i])\n",
    "        contexts_adv_addmodsent_only_adv.append(contexts_adv_addmodsent[i])\n",
    "        questions_adv_addmodsent_only_adv.append(questions_adv_addmodsent[i])\n",
    "        answers_adv_addmodsent_only_adv.append(answers_adv_addmodsent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787\n",
      "2560\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_adv_addonesent_only_adv))\n",
    "print(len(ids_adv_addsent_only_adv))\n",
    "print(len(ids_adv_addmodsent_only_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in ids_adv_addonesent_only_adv:\n",
    "    if id not in set(ids_adv_addsent_only_adv):\n",
    "        print(id)\n",
    "\n",
    "perturbed_contexts_ids = []\n",
    "for id in ids_adv_addsent_only_adv:\n",
    "    perturbed_contexts_ids.append(id[:24])\n",
    "\n",
    "perturbed_contexts_ids_modall = []\n",
    "for id in ids_adv_addmodsent_only_adv:\n",
    "    perturbed_contexts_ids_modall.append(id[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 783)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(perturbed_contexts_ids)), len(set(perturbed_contexts_ids_modall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad_adv/sample1k-HCVerifySample_only_adv.jsonl', 'w') as outfile:\n",
    "    for i in range(len(ids_adv_addonesent_only_adv)):\n",
    "        json.dump({\"id\": ids_adv_addonesent_only_adv[i],\n",
    "                   \"title\": titles_adv_addonesent_only_adv[i],\n",
    "                   \"context\": contexts_adv_addonesent_only_adv[i],\n",
    "                   \"question\": questions_adv_addonesent_only_adv[i],\n",
    "                   \"answers\": answers_adv_addonesent_only_adv[i]}, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad_adv/sample1k-HCVerifyAll_only_adv.jsonl', 'w') as outfile:\n",
    "    for i in range(len(ids_adv_addsent_only_adv)):\n",
    "        json.dump({\"id\": ids_adv_addsent_only_adv[i],\n",
    "                   \"title\": titles_adv_addsent_only_adv[i],\n",
    "                   \"context\": contexts_adv_addsent_only_adv[i],\n",
    "                   \"question\": questions_adv_addsent_only_adv[i],\n",
    "                   \"answers\": answers_adv_addsent_only_adv[i]}, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad_adv/sample1k-HCVerifyModAll_only_adv.jsonl', 'w') as outfile:\n",
    "    for i in range(len(ids_adv_addmodsent_only_adv)):\n",
    "        json.dump({\"id\": ids_adv_addmodsent_only_adv[i],\n",
    "                   \"title\": titles_adv_addmodsent_only_adv[i],\n",
    "                   \"context\": contexts_adv_addmodsent_only_adv[i],\n",
    "                   \"question\": questions_adv_addmodsent_only_adv[i],\n",
    "                   \"answers\": answers_adv_addmodsent_only_adv[i]}, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
